{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45a10198-9cf1-4fab-aed9-51056e5e70bb",
   "metadata": {},
   "source": [
    "# airflow 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e65fcff-5969-480b-bfb5-5ace7716df42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import airflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ac4df2-3713-411c-9eea-4369465e6a5d",
   "metadata": {},
   "source": [
    "```bash\n",
    "> pip install apache-airflow\n",
    "\n",
    "> airflow db init\n",
    "> airflow users create --username admin --password admin --firstname Anonymous --lastname Admin --role Admin --email addmin@example.org\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1995c50b-21b5-4a9b-b0ee-851167fac294",
   "metadata": {},
   "source": [
    "스케줄러, 웹 서버는 모두 터미널에서 실행되는 프로세스이므로 별도의 터미널 창을 열어 스케줄러와 웹 서버를 실행해 두어야 한다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b1e48f-4855-432c-8719-2f08c17d05db",
   "metadata": {},
   "source": [
    "```bash\n",
    "> airflow webserver\n",
    "\n",
    "> airflow scheduler\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "faafcfc9-04fe-4a32-a95b-93bf19a4be49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !airflow db init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bfc92db5-f6e1-4aaf-9e30-f6cf5802fefd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !airflow users create --username admin --password admin --firstname Anonymous --lastname Admin --role Admin --email addmin@example.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "371a4ef3-540a-406b-8472-15bed5225492",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: airflow [-h] GROUP_OR_COMMAND ...\n",
      "\n",
      "positional arguments:\n",
      "  GROUP_OR_COMMAND\n",
      "\n",
      "    Groups:\n",
      "      celery         Celery components\n",
      "      config         View configuration\n",
      "      connections    Manage connections\n",
      "      dags           Manage DAGs\n",
      "      db             Database operations\n",
      "      jobs           Manage jobs\n",
      "      kubernetes     Tools to help run the KubernetesExecutor\n",
      "      pools          Manage pools\n",
      "      providers      Display providers\n",
      "      roles          Manage roles\n",
      "      tasks          Manage tasks\n",
      "      users          Manage users\n",
      "      variables      Manage variables\n",
      "\n",
      "    Commands:\n",
      "      cheat-sheet    Display cheat sheet\n",
      "      dag-processor  Start a standalone Dag Processor instance\n",
      "      info           Show information about current Airflow and environment\n",
      "      kerberos       Start a kerberos ticket renewer\n",
      "      plugins        Dump information about loaded plugins\n",
      "      rotate-fernet-key\n",
      "                     Rotate encrypted connection credentials and variables\n",
      "      scheduler      Start a scheduler instance\n",
      "      standalone     Run an all-in-one copy of Airflow\n",
      "      sync-perm      Update permissions for existing roles and optionally DAGs\n",
      "      triggerer      Start a triggerer instance\n",
      "      version        Show the version\n",
      "      webserver      Start a Airflow webserver instance\n",
      "\n",
      "optional arguments:\n",
      "  -h, --help         show this help message and exit\n",
      "\n",
      "airflow command error: the following arguments are required: GROUP_OR_COMMAND, see help above.\n"
     ]
    }
   ],
   "source": [
    "!airflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2afdc18f-23e5-4933-ac87-ece99c772594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/jay/opt/anaconda3/envs/airflow/bin/airflow\n"
     ]
    }
   ],
   "source": [
    "!which airflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4ea6db2b-dbfd-4ad6-863e-7d3f33c4c7a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: airflow dags [-h] COMMAND ...\n",
      "\n",
      "Manage DAGs\n",
      "\n",
      "positional arguments:\n",
      "  COMMAND\n",
      "    backfill          Run subsections of a DAG for a specified date range\n",
      "    delete            Delete all DB records related to the specified DAG\n",
      "    list              List all the DAGs\n",
      "    list-import-errors\n",
      "                      List all the DAGs that have import errors\n",
      "    list-jobs         List the jobs\n",
      "    list-runs         List DAG runs given a DAG id\n",
      "    next-execution    Get the next execution datetimes of a DAG\n",
      "    pause             Pause a DAG\n",
      "    report            Show DagBag loading report\n",
      "    reserialize       Reserialize all DAGs by parsing the DagBag files\n",
      "    show              Displays DAG's tasks with their dependencies\n",
      "    show-dependencies\n",
      "                      Displays DAGs with their dependencies\n",
      "    state             Get the status of a dag run\n",
      "    test              Execute one single DagRun\n",
      "    trigger           Trigger a DAG run\n",
      "    unpause           Resume a paused DAG\n",
      "\n",
      "optional arguments:\n",
      "  -h, --help          show this help message and exit\n",
      "\n",
      "airflow dags command error: the following arguments are required: COMMAND, see help above.\n"
     ]
    }
   ],
   "source": [
    "!airflow dags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d600e360-44ca-44c8-9946-8a2a03f5d620",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:airflow]",
   "language": "python",
   "name": "conda-env-airflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
