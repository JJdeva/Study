딥러닝 모델 추론(inference)을 대규모로 수행하도록 인프라 구조를 관리하는 것은 비용이나 아키텍처 측면에서도 매우 인상적인 일

파이토치는 버전업을 하면서 대규모 제품화까지 지원하며 전 분야를 아우르는 end-to-end 플랫폼으로 발전했다.



모델을 제품으로 배포한다는 이야기는 다음과 같이 볼 수 있음

- 모델에 접근 가능한 네트워크 서비스 설정 (rest api로 요청)
- 모델을 표준화된 포맷으로 내보내어 최적화된 모델 프로세서나 특수 하드웨어, 클라우드 서비스에 출시할 수 있도록 준비
    - 파이토치는 ONNX (Open Neural Network Exchange)를 사용
- 더 큰 서비스로 확장 할 때 파이썬은 한계가 있음 -> C++ 파이토치 모델로 변경
- 모바일에 모델 자체를 탑재해서 내부에서 처리하게 하기







